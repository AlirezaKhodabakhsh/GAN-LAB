{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x26757af8230>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**NOTE:**\n",
    "Unlike Basic GANs that you played with Nodes, in DCGANs you will play with Channels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Information\n",
    "\n",
    "1. We have NO any pooling layer\n",
    "2. We have 2D batchnorm layer in both G and D.\n",
    "3. We have NO fully connected hidden layer (nn.Linear).\n",
    "4. ReLU in hidden layers - Tanh in final layer (Generators)\n",
    "5. LeakyReLU in hidden layers - NO activation in final layer (Discriminator)\n",
    "6. You will build a generator using 4 layers (3 hidden layers + 1 output layer)\n",
    "7. You will use 3 layers in your discriminator's neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def generator_block(C_in, C_out, K, S, final_layer=False):\n",
    "    if final_layer:\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(C_in, C_out, kernel_size = K, stride = S),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(C_in, C_out, kernel_size = K, stride = S),\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, C_noise, C_hidden, C_image):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            generator_block(C_noise   , 4*C_hidden, K=3, S=2),\n",
    "            generator_block(4*C_hidden, 2*C_hidden, K=4, S=1),\n",
    "            generator_block(2*C_hidden, C_hidden  , K=3, S=2),\n",
    "            generator_block(C_hidden  , C_image   , K=4, S=2, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discriminator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def discriminator_block(C_in, C_out, K, S, final_layer=False):\n",
    "    if final_layer:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size = K, stride = S),\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size = K, stride = S),\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.2)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, C_image, C_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            discriminator_block(C_image   , C_hidden  , K=4, S=2),\n",
    "            discriminator_block(C_hidden  , 2*C_hidden, K=4, S=2),\n",
    "            discriminator_block(2*C_hidden, 1         , K=4, S=2, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.model(x)\n",
    "        return x.view(x.shape[0], -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def get_noise(N_noise, C_noise, device='cpu'):\n",
    "    return torch.randn(N_noise, C_noise, device=device).view(-1, C_noise, 1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def get_loss_dis(gen, dis,\n",
    "                 real_image,\n",
    "                 N_noise, C_noise,\n",
    "                 criterion,\n",
    "                 device):\n",
    "\n",
    "    # some fake images will generate by Generator\n",
    "    x_hat = gen(get_noise(N_noise, C_noise, device=device)).detach()\n",
    "\n",
    "    # Discriminator determine how fake images are Fake (With Fake images)\n",
    "    y_hat_fake = dis(x_hat)\n",
    "    loss_fake = criterion(y_hat_fake, torch.zeros_like(y_hat_fake))\n",
    "\n",
    "    # Discriminator determine how real images are Realistic (With Real images)\n",
    "    y_hat_real = dis(real_image)\n",
    "    loss_real = criterion(y_hat_real, torch.ones_like(y_hat_real))\n",
    "\n",
    "    # Weighted Average\n",
    "    loss_dis = (real_image.shape[0] * loss_real + N_noise * loss_fake) / (real_image.shape[0] + N_noise)\n",
    "\n",
    "    return loss_dis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def get_loss_gen(gen, dis,\n",
    "                 N_noise, C_noise,\n",
    "                 criterion,\n",
    "                 device):\n",
    "\n",
    "    # some fake images will generate by Generator\n",
    "    x_hat = gen(get_noise(N_noise, C_noise, device=device))\n",
    "\n",
    "    # Discriminator determine how fake images are Fake (With Fake images)\n",
    "    y_hat_fake = dis(x_hat)\n",
    "    loss_gen = criterion(y_hat_fake, torch.ones_like(y_hat_fake))\n",
    "\n",
    "    return loss_gen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def save_model(gen, dis, epoch, root):\n",
    "    filename = root + f'\\model_epoch_{epoch}.pt'\n",
    "    torch.save({'epoch' : epoch,\n",
    "                'model_dis_state_dict' : dis.state_dict(),\n",
    "                'model_gen_state_dict' : gen.state_dict()},\n",
    "               filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# Sample numbers of noise and image\n",
    "N_noise = 128\n",
    "batch_size =128\n",
    "\n",
    "# Channels of noise and image\n",
    "C_noise = 64\n",
    "C_image = 1\n",
    "\n",
    "# Channels of hidden layers\n",
    "C_hidden_gen = 64\n",
    "C_hidden_dis = 16\n",
    "\n",
    "# lr/epoch/disp\n",
    "lr = 0.0002\n",
    "epochs= 50\n",
    "disp_freq=100\n",
    "\n",
    "# roots\n",
    "root_ds='D:\\GitHub\\gan-lab\\Dataset'\n",
    "root_models = \"D:\\GitHub\\gan-lab\\Models\"\n",
    "\n",
    "# devices\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Real Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST(root_ds, download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Models / Criterion / Optimizers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# get instance from models\n",
    "gen = Generator(C_noise, C_hidden_gen, C_image).to(device)\n",
    "dis = Discriminator(C_image, C_hidden_dis).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers\n",
    "optim_dis = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "optim_gen = torch.optim.Adam(gen.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "for x, y in dataloader:\n",
    "    x=x\n",
    "    y=y\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "image = get_noise(N_noise, C_noise, device=device)\n",
    "gen_out = gen(image)\n",
    "dis_out = dis(gen_out)\n",
    "print(image.shape)\n",
    "print(gen_out.shape)\n",
    "print(dis_out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "###### Epoch 1 #############################################\n",
      "############################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c21140c5ae1437a9fec029d3cb93af5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 50.20 MiB already allocated; 0 bytes free; 90.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_24784/1197334752.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0moptim_dis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mloss_dis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_loss_dis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreal_image\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mN_noise\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC_noise\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m         \u001B[0mloss_dis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m         \u001B[0moptim_dis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 307\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 154\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 50.20 MiB already allocated; 0 bytes free; 90.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss_gen_min = np.Inf\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    print(60 * \"#\")\n",
    "    print(6 * \"#\" + \" Epoch \" + str(epoch) + \" \" + 45 * \"#\")\n",
    "    print(60 * \"#\")\n",
    "\n",
    "    # Set mode on \"train mode\"\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "\n",
    "    for real_image, _ in tqdm(dataloader):\n",
    "        # GPU (model and data)\n",
    "        real_image=real_image.to(device)\n",
    "\n",
    "        # Discriminator Learning\n",
    "        optim_dis.zero_grad()\n",
    "        loss_dis = get_loss_dis(gen, dis, real_image, N_noise, C_noise, criterion, device)\n",
    "        loss_dis.backward()\n",
    "        optim_dis.step()\n",
    "\n",
    "        # Generator Learning\n",
    "        optim_gen.zero_grad()\n",
    "        loss_gen = get_loss_gen(gen, dis, N_noise, C_noise, criterion, device)\n",
    "        loss_gen.backward()\n",
    "        optim_gen.step()\n",
    "\n",
    "    #save_model(model_gen, model_dis, epoch, root_models)\n",
    "    print(\"Loss Dis: {:.2f}\\tLoss Gen: {:.2f}\".format(loss_dis,loss_gen))\n",
    "\n",
    "    gen.eval()\n",
    "    fake_images = gen(get_noise(25, C_noise, device=device))\n",
    "    show_tensor_images(fake_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}